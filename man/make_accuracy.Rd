% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/make_accuracy.R
\name{make_accuracy}
\alias{make_accuracy}
\title{Estimate accuracy metrics to evaluate point forecast}
\usage{
make_accuracy(future, main, dimension = "split", benchmark = NULL)
}
\arguments{
\item{future}{A \code{tibble} containing the forecasts for the models, splits, etc.}

\item{main}{A \code{tibble} containing the actual values.}

\item{dimension}{Character value. The forecast accuracy is estimated by \code{split} or \code{horizon}.}

\item{benchmark}{Character value. The forecast model used as benchmark for the relative mean absolute error (rMAE).}
}
\value{
A \code{tibble} containing the accuracy metrics for all series
   models etc.
}
\description{
This function estimates several accuracy metrics to evaluate
  the accuracy of point forecasts. Either along the forecast horizon or
  along the train-test-splits. By default, the following accuracy metrics
  are provided:

   \itemize{
      \item{\code{ME}: mean error}
      \item{\code{MAE}: mean absolute error}
      \item{\code{MSE}: mean squared error}
      \item{\code{RMSE}: root mean squared error}
      \item{\code{MAPE}: mean absolute percentage error}
      \item{\code{sMAPE}: scaled mean absolute percentage error}
      \item{\code{MPE}: mean percentage error}
      \item{\code{rMAE}: relative mean absolute error}
      }
}
